---
title: A la d√©couverte de Vector 
date: "2020-04-14T12:00:00.000Z"
description: Vector est un router de donn√©es d'observabilit√© haute-performance, open-source et √©crit en Rust. Un Logstash killer ?      
template: "post"
draft: false
slug: "decouverte-vector"
category: "Dev"
language: üá´üá∑
tags:
  - "Monitoring"
  - "Vector"
  - "Rust"
  - "Logstash"
socialImage: "/media/vector/vector.png"
---

## TL/DR
En 2 briques, `Logstash` ? ETL ! `Rust` ? [Vector](https://vector.dev/) !
On peut effectivement d√©crire Vector comme un Logstash qu'on aurait r√©√©crit en Rust, avec tous les avantages inh√©rents au langage (performance, binaire natif), mais les d√©fauts d'une solution encore tr√®s jeune (nombre de modules limit√©s, peu de r√©f√©rences). 
On notera que la documentation semble plut√¥t bien faite, et que les composants natifs permettent de g√©rer beaucoup de use-case simple de monitoring. 
Et comme on peut convenir que Logstash n'est pas le meilleur produit du monde, esp√©rons que Vector trouve sa place dans les prochains mois dans la communaut√©. 
Et en plus, ca tombe bien, Vector propose nativement des modules √©quivalents √† ceux de Logstash, ce qui fait que la migration ne sera pas compliqu√©e !     

## Apr√®s-tout, on a le temps non ? #Confinement

[Vector](https://vector.dev/) se d√©fini comme un routeur de donn√©es d'observabilit√© haute-performance, qui permet la collecte, la transformation et l'envoi d'√©v√™nements (logs et/ou m√©triques).

### Fonctionnement conceptuel
![](/d3rwan-blog/media/vector/concept.png)

Il s'agit basiquement d'un ETL qui s'appuie sur les notions suivantes:
- **Source** (aka. E / Extract)

R√©cup√©ration des donn√©es brutes depuis l'endroit o√π elles sont produites. 
Par exemple, on pourra [lire les logs dans un fichier](https://vector.dev/docs/reference/sources/file/), [√©couter une file Kafka](https://vector.dev/docs/reference/sources/kafka/) ou [r√©cup√©rer des m√©triques de StatsD](https://vector.dev/docs/reference/sources/statsd/)

- **Transform** (aka. T / Transform)

Transformation des donn√©es brutes, ou du flux complet de donn√©es,
Par exemple, on pourra [filtrer des entr√©es](https://vector.dev/docs/reference/transforms/filter/) ou encore [parser un log selon une expression r√©guli√®re](https://vector.dev/docs/reference/transforms/regex_parser/) 

- **Sink** (aka. L / Load)

Destination des donn√©es lues et transform√©es. Chaque module enverra les donn√©es de mani√®re unitaire ou sous la forme d'un stream en fonction du service cible.
Par exemple, on pourra [sauvegarder les donn√©es brutes sous Amazon S3](https://vector.dev/docs/reference/sinks/aws_s3/), les [indexer dans un cluster Elasticsearch](https://vector.dev/docs/reference/sinks/elasticsearch/) ou les [exposer √† Prometheus](https://vector.dev/docs/reference/sinks/prometheus/)

### Fonctionnalit√©s

#### Rapide

Ecrit en Rust, Vector est tr√®s rapide avec une gestion efficiente de la m√©moire. 
Le tout sans runtime, ni garbage collector.

#### Un outil unique, de la source √† la destination

Vector propose plusieurs strat√©gies de d√©ploiement afin de pouvoir √™tre utilis√© par tous, quelque-soit le contexte. 

- [D√©ploiement en tant que D√©mon](https://vector.dev/docs/setup/deployment/strategies/#daemon)

Ici, on lancera une instance de Vector en t√¢che de fond pour collecter *toutes* les donn√©es du serveur h√¥te 
![](/d3rwan-blog/media/vector/strategy_daemon.png)

- [D√©ploiement en tant que Sidecar](https://vector.dev/docs/setup/deployment/strategies/#sidecar)

Dans cette strat√©gie, on lancera une instance de Vector par service √† monitorer.
![](/d3rwan-blog/media/vector/strategy_sidecar.png)

- [D√©ploiement en tant que Service](https://vector.dev/docs/setup/deployment/strategies/#service)

Ici, Vector est lanc√© en tant qu'un service d√©di√©. 
![](/d3rwan-blog/media/vector/strategy_service.png)

En utilisant et/ou combinant ces strat√©gies, on peut donc d√©finir des topologies d'architecture de collecte de donn√©es

- [Collecte distribu√©e](https://vector.dev/docs/setup/deployment/topologies/#distributed)

Dans cette topologie, chaque instance de Vector va directement envoyer les donn√©es au(x) service(s) cibles. 
Il s'agit du cas le plus simple, et qui permet de _scaler_ facilement. 
N√©anmoins, il peut induire des pertes de performance locales ou de donn√©es.
 
![](/d3rwan-blog/media/vector/topology_distributed.png)

- [Collecte Centralis√©e](https://vector.dev/docs/setup/deployment/topologies/#centralized)

Ici, chaque instance de Vector va envoyer les donn√©es √† une instance centrale, charg√©e d'effectuer les op√©rations les plus co√ªteuses. 
De fait, moins d'impact sur les performances locales des applicatifs, mais un service centrale en tant que [SPOF](https://fr.wikipedia.org/wiki/Point_de_d%C3%A9faillance_unique)  
![](/d3rwan-blog/media/vector/topology_centralized.png)

- [Collecte Stream√©e](https://vector.dev/docs/setup/deployment/topologies/#stream-based)

Variante de la topologie pr√©c√©dente, dans laquelle on va rajouter un broker en amont du service centrale afin de supprimer le SPOF.  
Cette topologie est la plus scalable et durable, mais aussi la plus complexe √† mettre en place.  

![](/d3rwan-blog/media/vector/topology_stream.png)

#### Simplicit√© de d√©ploiement

Concu en Rust, Vector se pr√©sente donc sous la forme d'un binaire cross-compil√© pour l'os cible, et ne n√©cessite pas de runtime type JVM

## Bon, OK, mais ca marche au moins ?

Pour tester Vector, je vais m'inspirer d'un post pr√©c√©dent : [Une stack ELK from scratch avec Docker](https://d3rwan.github.io/d3rwan-blog/posts/elk-depuis-zero)

![](/d3rwan-blog/media/vector/archi.png)*Architecture de notre POC* 

Dans le cas pr√©sent, je vais m'appuyer sur :

- Elasticsearch, comme moteur d‚Äôindexation, de recherche & d‚Äôanalytics,
- Kibana, comme IHM de visualisation et de g√©n√©ration de tableaux de bord interactifs
- Vector, en tant que service central, pour transformer les donn√©es et les envoyer vers Elasticsearch,
- Kafka, en tant que broker en amont de ma stack de monitoring
- Vector, en tant qu'agent, pour r√©cup√©rer les donn√©es sources et les envoyer vers Kafka

> On se positionne donc dans la topologie de [Collecte Stream√©e](https://vector.dev/docs/setup/deployment/topologies/#stream-based) d√©crite ci-avant

L‚Äôensemble des services et des interactions sont d√©crites dans un fichier docker-compose.yml:

`gist:d3rwan/13aba18e159c340b2947992bfbb45f81#docker-compose.yml`

Le service central Vector est configur√© comme suit:
- Lecture des √©v√™nements depuis le broker Kafka
- Parsing du JSON de l'√©v√™nement envoy√© depuis l'agent Vector
- Parsing Grok (format Logstash) de la ligne de log brute
- Indexation vers Elasticsearch

`gist:d3rwan/13aba18e159c340b2947992bfbb45f81#vector.toml`

Fun fact, il est possible de [tester unitairement la configuration](https://vector.dev/docs/reference/tests/) avec Vector, comme on peut le voir dans la section [[tests]] du fichier

On pourra √©galement noter que chaque step de configuration se base sur au moins un step pr√©c√©dent. 
 

C√¥t√© webapp, on ajoute un agent Vector configur√© comme suit:
- Lecture des logs depuis un fichier
- Envoi vers le broker Kafka

`gist:d3rwan/13aba18e159c340b2947992bfbb45f81#agent_vector.toml`

> Le projet de test complet est disponible sur github [discovering_vector](https://github.com/d3rwan/discovering_vector)

Il ne me reste qu'√† lancer tous mes services

```bash 
 docker-compose build
 docker-compose up
```

Puis me rendre sur ma webapp (dans mon cas, http://localhost:80)
![](/d3rwan-blog/media/elk/joliadmin.png)*Exemple d‚Äôapplication web (source: [https://github.com/sbilly/joli-admin](https://github.com/sbilly/joli-admin))*

Apr√®s une rapide navigation, je peux me rendre sur mon IHM Kibana (dans mon cas, http://localhost:5601), puis dans l'onglet `Management` puis `Kibana > Index Patterns`

![](/d3rwan-blog/media/vector/add_index_kibana.png)_Ajout du pattern d'index vector-\*_

Et voil√† ! Un index `vector-YYYY.MM.DD` a √©t√© cr√©e et contient bien mes logs applicatifs. 
A partir de l√†, je vais pouvoir cr√©er mes indexs, recherches visualisations, dashboards et autre canvas dans Kibana, et pouvoir utiliser ces informations de monitoring.

Pour conclure, il est effectivement assez facile d'utiliser [Vector](https://vector.dev/) comme remplacant de logtash/beats dans une stack Elastic, et le fait est que ca fonctionne.
Reste √† voir sur la dur√©e si les gains de performance annonc√© sont r√©els, et si le projet arrive durablement √† s'imposer dans la communaut√©. 
En attendant, m√™me tr√®s jeune, ce projet est plein de promesses et de bonnes id√©es (tests unitaires, multi-topologies natives, ...), et m√©rite donc qu'on y jette un oeil!

